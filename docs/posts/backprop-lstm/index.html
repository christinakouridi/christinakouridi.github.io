<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta name="author" content="Christina Kouridi">
    <meta name="description" content="/">
    <meta name="keywords" content="blog,developer,personal">

    <meta property="og:site_name" content="Christina Kouridi">
    <meta property="og:title" content="
  Deriving backpropagation equations for an LSTM - Christina Kouridi
">
    <meta property="og:description" content="">
    <meta property="og:type" content="website">
    <meta property="og:url" content="/posts/backprop-lstm/">
    <meta property="og:image" content="/">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="/posts/backprop-lstm/">
    <meta name="twitter:image" content="/">

    <base href="/posts/backprop-lstm/">
    <title>
  Deriving backpropagation equations for an LSTM - Christina Kouridi
</title>

    <link rel="canonical" href="/posts/backprop-lstm/">
    
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" integrity="sha384-hWVjflwFxL6sNzntih27bfxkr27PmbbK/iSvJ+a4+0owXq79v+lsFkW54bOGbiDQ" crossorigin="anonymous">
    
    <link  rel="stylesheet" href="https://fonts.googleapis.com/css?family=Fira+Mono:400,700">
    <link rel="stylesheet" href="/css/normalize.min.css">
    <link rel="stylesheet" href="/css/style.min.css">

    

    

    <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

    
      <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Christina Kouridi">
      <link href="/index.xml" rel="feed" type="application/rss+xml" title="Christina Kouridi" />
    

    <meta name="generator" content="Hugo 0.111.3">

    <style>
      .equation {
        border-radius: .3rem;
        margin: 2rem 0;
        overflow-x:auto;
        padding: 1rem 1rem;
      }
      .katex-display > .katex {
        text-align: left !important;
      }
    </style>
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css" integrity="sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X" crossorigin="anonymous">


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js" integrity="sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz" crossorigin="anonymous"></script>


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>

<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: "$$", right: "$$", display: true},
        {left: "$", right: "$", display: false}
      ]
    });
  });
</script>

    

  </head>

  <body class="">
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">Christina Kouridi</a>
    <input type="checkbox" id="menu-control"/>
    <label class="menu-mobile  float-right " for="menu-control">
      <span class="btn-mobile  float-right ">&#9776;</span>
      <ul class="navigation-list">
        
          
            <li class="navigation-item  align-center ">
              <a class="navigation-link" href="/about">About</a>
            </li>
          
            <li class="navigation-item  align-center ">
              <a class="navigation-link" href="/posts">Blog</a>
            </li>
          
            <li class="navigation-item  align-center ">
              <a class="navigation-link" href="/research">Research</a>
            </li>
          
            <li class="navigation-item  align-center ">
              <a class="navigation-link" href="https://christinakouride.wixsite.com/ckouridi-portfolio">Photography</a>
            </li>
          
        
        
      </ul>
    </label>
  </section>
</nav>


      <div class="content">
        
  <section class="container post">
  <article>
    <header>
      <h1 class="title">Deriving backpropagation equations for an LSTM</h1>
      <h2 class="date">June 19, 2019</h2>

      
    </header>

    <p>In this post I will derive the backpropagation equations for a LSTM cell in vectorised form. It assumes basic knowledge of LSTMs and backpropagation, which you can refresh at <a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a> and <a href="http://arunmallya.github.io/writeups/nn/backprop.html">A Quick Introduction to Backpropagation</a>.</p>
<h4 id="derivations">Derivations</h4>
<h5 id="forward-propagation">Forward propagation</h5>
<p>We will firstly remind ouselves of the forward propagation equations. The nomenclature followed is demonstrated in Figure 1. All equations correspond to one time step.</p>
<figure><img src="images/blog_bplstm_1.png" width="75%"/><figcaption>
            <h4>Figure 1: Architecture of a LSTM memory cell at timestep t</h4>
        </figcaption>
</figure>


  <div class="equation">$$ \begin{aligned}
&amp;h\_{t-1} \in  \mathbb{R}^{n\_{h}}, &amp; \hskip{31mu} x\_{t} \in  \mathbb{R}^{n\_{x}} \\\
&amp;z\_{t}= [h\_{t-1}, x\_{t}] \\\
\end{aligned} $$

$$ \begin{aligned}
&amp;a\_{f}= W\_{f}\cdot z\_{t} &#43; b\_{f},&amp; \hskip{31mu}  f\_{t}= \sigma(a\_{f}) \\\
&amp;a\_{i}= W\_{i}\cdot z\_{t} &#43; b\_{i},&amp; \hskip{40mu}  i\_{t}= \sigma(a\_{i}) \\\
&amp;a\_{o}= W\_{o}\cdot z\_{t} &#43; b\_{o},&amp; \hskip{34mu}  o\_{t}= \sigma(a\_{o})  \\\
&amp;a\_{c}= W\_{c}\cdot z\_{t} &#43; b\_{c},&amp; \hskip{36mu}  \hat{c}\_t=  tanh(a\_{c}) \\\
\end{aligned} $$

$$ \begin{aligned}
&amp;{c}\_t=  i\_{t}\odot \hat{c}\_t &#43; f\_{t}\odot c\_{t-1} \\\
&amp;{h}\_t=  o\_{t}\odot tanh(c\_{t}) \\\
\end{aligned} $$

$$ \begin{aligned}
&amp;v\_{t}= W\_{v}\cdot h\_{t} &#43; b\_{v} \\\
&amp;\hat{y}\_t= softmax(v\_{t})
\end{aligned} $$
  </div>
<h5 id="backward-propagation">Backward propagation</h5>
<p>Backpropagation through a LSTM is not as straightforward as through other common Deep Learning architectures, due to the special way its underlying layers interact. Nonetheless, the approach is largely the same; identifying dependencies and recursively applying the chain rule.</p>
<figure><img src="images/blog_bplstm_2.png" width="80%"/><figcaption>
            <h4>Figure 2: Backpropagation through a LSTM memory cell</h4>
        </figcaption>
</figure>

<p>Cross-entropy loss with a softmax function are used at the output layer. The standard definition of the derivative of the cross-entropy loss ($\frac{\partial J}{\partial v_{t}}$) is used directly; a detailed derivation can be found here.</p>
<h5 id="output">Output</h5>

  <div class="equation">$$ \begin{aligned}
&amp;\frac{\partial J}{\partial v\_{t}} = \hat{y}\_t - y\_{t} \\\
&amp;\frac{\partial J}{\partial W\_{v}} = \frac{\partial J}{\partial v\_{t}} \cdot \frac{\partial v\_{t}}{\partial W\_{v}} \Rightarrow \frac{\partial J}{\partial W\_{v}} = \frac{\partial J}{\partial v\_{t}} \cdot h\_{t}^T \\\
&amp;\frac{\partial J}{\partial b\_{v}} = \frac{\partial J}{\partial v\_{t}} \cdot \frac{\partial v\_{t}}{\partial b\_{v}} \Rightarrow \frac{\partial J}{\partial b\_{v}} = \frac{\partial J}{\partial v\_{t}} \end{aligned} $$
  </div>
<h5 id="hidden-state">Hidden state</h5>

  <div class="equation">$$ \begin{aligned}
&amp;\frac{\partial J}{\partial h\_{t}} = \frac{\partial J}{\partial v\_{t}} \cdot \frac{\partial v\_{t}}{\partial h\_{t}} \Rightarrow \frac{\partial J}{\partial h\_{t}} = W\_{v}^T \cdot \frac{\partial J}{\partial v\_{t}} \\\
&amp;\frac{\partial J}{\partial h\_{t}} &#43;= \frac{\partial J}{\partial h\_{next}}
\end{aligned} $$
  </div>
<h5 id="output-gate">Output gate</h5>

  <div class="equation">$$ \begin{aligned}
&amp;\frac{\partial J}{\partial o\_{t}} = \frac{\partial J}{\partial h\_{t}} \cdot \frac{\partial h\_{t}}{\partial o\_{t}} \Rightarrow \frac{\partial J}{\partial o\_{t}} = \frac{\partial J}{\partial h\_{t}} \odot tanh(c\_{t}) \\\
\end{aligned} $$

$$ \begin{aligned}
&amp;\frac{\partial J}{\partial a\_{o}} = \frac{\partial J}{\partial o\_{t}} \cdot \frac{\partial o\_{t}}{\partial a\_{o}} \Rightarrow \frac{\partial J}{\partial a\_{o}} = \frac{\partial J}{\partial h\_{t}} \odot tanh(c\_{t}) \odot \frac{d(\sigma (a\_{o}))}{da\_{o}}  \\\ 
&amp;\Rightarrow \frac{\partial J}{\partial a\_{o}} = \frac{\partial J}{\partial h\_{t}} \odot tanh(c\_{t}) \odot \sigma (a\_{o})(1- \sigma (a\_{o}))  \\\ 
&amp;\Rightarrow \frac{\partial J}{\partial a\_{o}} = \frac{\partial J}{\partial h\_{t}} \odot tanh(c\_{t}) \odot o\_{t}(1- o\_{t}) \\\
\end{aligned} $$

$$ \begin{aligned}
&amp;\frac{\partial J}{\partial W\_{o}} = \frac{\partial J}{\partial a\_{o}} \cdot \frac{\partial a\_{o}}{\partial W\_{o}}  \Rightarrow \frac{\partial J}{\partial W\_{o}} = \frac{\partial J}{\partial a\_{o}} \cdot z\_{t}^T \\\
&amp;\frac{\partial J}{\partial b\_{o}} = \frac{\partial J}{\partial a\_{o}} \cdot \frac{\partial a\_{o}}{\partial b\_{o}} \Rightarrow \frac{\partial J}{\partial b\_{o}} = \frac{\partial J}{\partial a\_{o}}
\end{aligned} $$
  </div>
<h5 id="cell-state">Cell state</h5>

  <div class="equation">$$ \begin{aligned}
\frac{\partial J}{\partial c\_{t}} = \frac{\partial J}{\partial h\_{t}} \cdot \frac{\partial h\_{t}}{\partial c\_{t}} \Rightarrow \frac{\partial J}{\partial c\_{t}} = \frac{\partial J}{\partial h\_{t}} \odot o\_{t} \odot (1-tanh(c\_{t})^2) \\\
\end{aligned} $$

$$ \begin{aligned}
\frac{\partial J}{\partial c\_{t}} &#43;= \frac{\partial J}{\partial c\_{next}} \\\
\end{aligned} $$

$$ \begin{aligned}
&amp;\frac{\partial J}{\partial \hat{c}\_t} = \frac{\partial J}{\partial c\_{t}} \cdot \frac{\partial c\_{t}}{\partial \hat{c}\_t} \Rightarrow \frac{\partial J}{\partial \hat{c}\_t} = \frac{\partial J}{\partial c\_{t}} \odot i\_{t} \\\
\end{aligned} $$

$$ \begin{aligned}
&amp;\frac{\partial J}{\partial a\_{c}} = \frac{\partial J}{\partial \hat{c}\_t} \cdot \frac{\partial \hat{c}\_t}{\partial a\_{c}} \Rightarrow \frac{\partial J}{\partial a\_{c}} = \frac{\partial J}{\partial c\_{t}} \odot i\_{t} \odot \frac{d(tanh(a\_{c}))}{da\_{c}} \\\
&amp;\Rightarrow \frac{\partial J}{\partial a\_{c}} = \frac{\partial J}{\partial c\_{t}} \odot i\_{t} \odot (1 - tanh(a\_{c})^2) \\\ 
&amp;\Rightarrow \frac{\partial J}{\partial a\_{c}} = \frac{\partial J}{\partial c\_{t}} \odot i\_{t} \odot (1 - \hat{c}\_t^2) \\\
\end{aligned} $$

$$ \begin{aligned}
&amp;\frac{\partial J}{\partial W\_{c}} = \frac{\partial J}{\partial a\_{c}} \cdot \frac{\partial a\_{c}}{\partial W\_{c}} \Rightarrow \frac{\partial J}{\partial W\_{c}} = \frac{\partial J}{\partial a\_{c}} \cdot z\_{t}^T \\\
\end{aligned} $$

$$ \begin{aligned}
&amp;\frac{\partial J}{\partial b\_{c}} = \frac{\partial J}{\partial a\_{c}} \cdot \frac{\partial a\_{c}}{\partial b\_{c}} \Rightarrow \frac{\partial J}{\partial b\_{c}} = \frac{\partial J}{\partial a\_{c}}
\end{aligned} $$
  </div>
<h5 id="input-gate">Input gate</h5>

  <div class="equation">$$ \begin{aligned}
&amp;\frac{\partial J}{\partial i\_{t}} = \frac{\partial J}{\partial c\_{t}} \cdot \frac{\partial c\_{t}}{\partial i\_{t}} \Rightarrow \frac{\partial J}{\partial i\_{t}} = \frac{\partial J}{\partial c\_{t}} \odot \hat{c}\_t \\\
\end{aligned} $$

$$ \begin{aligned}
&amp;\frac{\partial J}{\partial a\_{i}} = \frac{\partial J}{\partial i\_{t}} \cdot \frac{\partial i\_{t}}{\partial a\_{i}} \Rightarrow \frac{\partial J}{\partial a\_{i}} = \frac{\partial J}{\partial c\_{t}} \odot \hat{c}\_t \odot \frac{d(\sigma (a\_{i}))}{da\_{i}} \\\
&amp;\Rightarrow \frac{\partial J}{\partial a\_{i}} = \frac{\partial J}{\partial c\_{t}} \odot \hat{c}\_t \odot \sigma (a\_{i})(1- \sigma (a\_{i})) \\\ 
&amp;\Rightarrow \frac{\partial J}{\partial a\_{i}} = \frac{\partial J}{\partial c\_{t}} \odot \hat{c}\_t \odot i\_{t}(1- i\_{t}) \\\
\end{aligned} $$

$$ \begin{aligned}
&amp;\frac{\partial J}{\partial W\_{i}} = \frac{\partial J}{\partial a\_{i}} \cdot \frac{\partial a\_{i}}{\partial W\_{i}}  \Rightarrow \frac{\partial J}{\partial W\_{i}} = \frac{\partial J}{\partial a\_{i}} \cdot z\_{t}^T \\\
\end{aligned} $$

$$ \begin{aligned}
\frac{\partial J}{\partial b\_{i}} = \frac{\partial J}{\partial a\_{i}} \cdot \frac{\partial a\_{i}}{\partial b\_{i}} \Rightarrow \frac{\partial J}{\partial b\_{i}} = \frac{\partial J}{\partial a\_{i}}
\end{aligned} $$
  </div>
<h5 id="forget-gate">Forget gate</h5>

  <div class="equation">$$ \begin{aligned}
\frac{\partial J}{\partial f\_{t}} = \frac{\partial J}{\partial c\_{t}} \cdot \frac{\partial c\_{t}}{\partial f\_{t}} \Rightarrow \frac{\partial J}{\partial f\_{t}} = \frac{\partial J}{\partial c\_{t}} \odot c\_{t-1} \\\
\end{aligned} $$

$$ \begin{aligned}
&amp;\frac{\partial J}{\partial a\_{f}} = \frac{\partial J}{\partial f\_{t}} \cdot \frac{\partial f\_{t}}{\partial a\_{f}} \Rightarrow \frac{\partial J}{\partial a\_{f}} = \frac{\partial J}{\partial c\_{t}} \odot c\_{t-1} \odot \frac{d(\sigma (a\_{f}))}{da\_{f}} \\\ 
&amp;\Rightarrow \frac{\partial J}{\partial a\_{f}} = \frac{\partial J}{\partial c\_{t}} \odot c\_{t-1} \odot \sigma (a\_{f})(1- \sigma (a\_{f}) \\\ 
&amp;\Rightarrow \frac{\partial J}{\partial a\_{f}} = \frac{\partial J}{\partial c\_{t}} \odot c\_{t-1} \odot f\_{t}(1- f\_{t}) \\\
\end{aligned} $$

$$ \begin{aligned}
&amp;\frac{\partial J}{\partial W\_{f}} = \frac{\partial J}{\partial a\_{f}} \cdot \frac{\partial a\_{f}}{\partial W\_{f}}  \Rightarrow \frac{\partial J}{\partial W\_{f}} = \frac{\partial J}{\partial a\_{f}} \cdot z\_{t}^T \\\
&amp;\frac{\partial J}{\partial b\_{f}} = \frac{\partial J}{\partial a\_{f}} \cdot \frac{\partial a\_{f}}{\partial b\_{f}} \Rightarrow \frac{\partial J}{\partial b\_{f}} = \frac{\partial J}{\partial a\_{f}}
\end{aligned} $$
  </div>
<h5 id="input">Input</h5>

  <div class="equation">$$ \begin{aligned}
&amp;\frac{\partial J}{\partial z\_{t}} = \frac{\partial J}{\partial a\_{f}} \cdot \frac{\partial a\_{f}}{\partial z\_{t}} &#43; \frac{\partial J}{\partial a\_{i}} \cdot \frac{\partial a\_{i}}{\partial z\_{t}} &#43; \frac{\partial J}{\partial a\_{o}} \cdot \frac{\partial a\_{o}}{\partial z\_{t}} &#43; \frac{\partial J}{\partial a\_{c}} \cdot \frac{\partial a\_{c}}{\partial z\_{t}}  \\\ 
&amp;\Rightarrow \frac{\partial J}{\partial z\_{t}} =  W\_{f}^T \cdot \frac{\partial J}{\partial a\_{f}} &#43;W\_{i}^T \cdot \frac{\partial J}{\partial a\_{i}} &#43; W\_{o}^T \cdot \frac{\partial J}{\partial a\_{o}} &#43; W\_{c}^T \cdot \frac{\partial J}{\partial a\_{c}} \\\
\end{aligned} $$

$$ \begin{aligned}
&amp;\frac{\partial J}{\partial h\_{t-1}} = \frac{\partial J}{\partial z\_{t}}[:n\_{h}, :] \\\
&amp;\frac{\partial J}{\partial c\_{t-1}} = \frac{\partial J}{\partial c\_{t}} \cdot \frac{\partial c\_{t}}{\partial c\_{t-1}} \Rightarrow \frac{\partial J}{\partial c\_{t-1}} = \frac{\partial J}{\partial c\_{t}} \odot f\_{t}
\end{aligned} $$
  </div>
<p>The above equations for forward propagation and back propagation will be calculated T times (number of time steps) in each training iteration. At the end of each training iteration, the weights will be updated using the accumulated cost gradient with respect to each weight for all time steps. Assuming Stochastic Gradient Descent, the update equations are the following:</p>

  <div class="equation">$$ \begin{aligned}
&amp;\frac{\partial J}{\partial W\_{f}} = \sum\limits\_{t}^T \frac{\partial J}{\partial W\_{f}^t}, \hskip{31mu} W\_{f} &#43;= \alpha * \frac{\partial J}{\partial W\_{f}} \\\
&amp;\frac{\partial J}{\partial W\_{i}} = \sum\limits\_{t}^T \frac{\partial J}{\partial W\_{i}^t}, \hskip{31mu} W\_{i} &#43;= \alpha * \frac{\partial J}{\partial W\_{i}} \\\
&amp;\frac{\partial J}{\partial W\_{o}} = \sum\limits\_{t}^T \frac{\partial J}{\partial W\_{o}^t}, \hskip{31mu} W\_{o} &#43;= \alpha * \frac{\partial J}{\partial W\_{o}} \\\
&amp;\frac{\partial J}{\partial W\_{c}} = \sum\limits\_{t}^T \frac{\partial J}{\partial W\_{c}^t}, \hskip{31mu} W\_{c} &#43;= \alpha * \frac{\partial J}{\partial W\_{c}} \\\
&amp;\frac{\partial J}{\partial W\_{v}} = \sum\limits\_{t}^T \frac{\partial J}{\partial W\_{v}^t}, \hskip{31mu} W\_{v} &#43;= \alpha * \frac{\partial J}{\partial W\_{v}} \\\
\end{aligned} $$
  </div>
<p>In the <a href="/posts/implement-lstm">next post</a>, we will implement the above equations using Numpy and train the resulting LSTM model on real data.</p>

  </article>

  <br/>

  
  
</section>

      </div>
      
        <footer class="footer">
  <section class="container">
    
      <div class="sns-shares sp-sns-shares">
        
        
        
        
        
      </div>
    
    
     © 2023    ·  Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/naro143/hugo-coder-portfolio">CoderPortfolio</a>. 

  </section>
</footer>
<div class="fixed-bar">
  <section class="container">
    
    
      <div class="sns-shares pc-sns-shares">
        
        
        
        
        
      </div>
    
  </section>
</div>

      
    </main>

    

  <script src="/js/app.js"></script>
  
  </body>
</html>
